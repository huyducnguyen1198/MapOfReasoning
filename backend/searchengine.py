# -*- coding: utf-8 -*-
"""searchEngine

Automatically generated by Colaboratory.

Original file is located at
	https://colab.research.google.com/drive/1H3-erpuufj2najcDBL8hvPjHJaa5bhtj

## Preparation

### Load trained faiss
"""

import faiss
import numpy as np
from transformers import AutoTokenizer, AutoModel
import torch
from tqdm import tqdm
import pandas as pd
import pickle
from transformers import GPT2Tokenizer, GPT2LMHeadModel
from transformers import BertTokenizer, BertModel, BertForMaskedLM

"""### Load trained faiss"""

with open('./faiss_index/para_trained_index.index', 'rb') as f:
  para_train_index = pickle.load(f)
  para_train_index = para_train_index.iloc[0]


with open('./faiss_index/sent_trained_index.index', 'rb') as f:
  sent_train_index = pickle.load(f)
  sent_train_index = sent_train_index.iloc[0]

with open('./faiss_index/titSec_trained_index.index', 'rb') as f:
  titSec_train_index = pd.read_pickle(f)
  titSec_train_index = titSec_train_index.iloc[0]

"""### Load dataset"""

para = pd.read_csv("./dataset/paragraph.csv")
sent = pd.read_csv("./dataset/sentence.csv")
titSec = pd.read_csv("./dataset/titSec.csv")
title = pd.read_csv("./dataset/title.csv")
section = pd.read_csv("./dataset/section.csv")

"""### Text Embedding Function"""

model_name = "bert" # or "bert"
if model_name == 'bert':
  # Load the model and tokenizer
  model_name = "bert-base-uncased"
  tokenizer = AutoTokenizer.from_pretrained(model_name)
  device = "cuda" if torch.cuda.is_available() else "cpu"
  model = AutoModel.from_pretrained(model_name).to(device)

  def get_embedding(sentence):
	  inputs = tokenizer(sentence, return_tensors="pt", padding=True, truncation=True)
	  inputs = inputs.to(device)
	  output = model(**inputs)
	  embedding = output.last_hidden_state.mean(dim=1).detach().cpu().numpy()
	  return embedding


"""# sort paragraph on similarity using finetuned bert"""

model_path = "checkpoint-4000/"
model_name = "bert-base-uncased"

tokenizer = AutoTokenizer.from_pretrained(model_name)
fmodel = BertForMaskedLM.from_pretrained(model_path)
fmodel = fmodel.bert
device = "cuda" if torch.cuda.is_available() else "cpu"

model = fmodel.to(device)

def get_embedding_similarity(sentence):
  inputs = tokenizer(sentence, return_tensors="pt", padding=True, truncation=True)
  inputs = inputs.to(device)
  output = model(**inputs)
  embedding = output.last_hidden_state.mean(dim=1).detach().cpu().numpy()
  return embedding

def calculate_similarity(embedding1, embedding2):
  return np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))


"""### sort the result in sentences"""
def searchBySentence(sentence, num_results=10):
	reference_embedding = get_embedding_similarity(sentence)

	# sentence
	# search similarity
	result = sent_train_index.search(reference_embedding, num_results)
	reference_embedding_squeeze = reference_embedding.squeeze()
	result_texts = [sent.loc[i]['sentence'] for i in result[1][0]]
	result_embedding = [get_embedding(t).squeeze() for t in result_texts]
	result_similarity = [calculate_similarity(reference_embedding_squeeze, e) for e in result_embedding]

	# sort result_texts using result_similairty
	sent_result_df = sent.loc[result[1][0]]
	sent_result_df['similarity'] = result_similarity
	sent_result_df = sent_result_df.sort_values('similarity', ascending=False)

	# merge with para
	sent_result_df = pd.merge(sent_result_df, para[['paragraph_id', 'paragraph','title_id', 'section_id',]], on='paragraph_id')
	sent_result_df = sent_result_df[['title_id', 'section_id', 'paragraph_id', 'sentence_id', 'sentence', 'paragraph', 'similarity']]

	#merge with seciton

	sent_result_df = pd.merge(sent_result_df, section[['section_id', 'title_id', 'section']], on=['title_id', 'section_id'])
	sent_result_df = sent_result_df[['title_id', 'section_id', 'section', 'paragraph_id', 'sentence_id', 'sentence', 'paragraph', 'similarity']]

	# merge with title
	title.rename(columns={'id': 'title_id'}, inplace=True)
	sent_result_df = pd.merge(sent_result_df, title[['title_id', 'title']], on='title_id')
	sent_result_df = sent_result_df[['title_id', 'title', 'section_id', 'section', 'paragraph_id', 'sentence_id', 'sentence', 'paragraph', 'similarity']]

	sent_result_df['titSec'] = sent_result_df['title'] + ' ' + sent_result_df['section']
	return sent_result_df


"""### sort the result in paragraphs

"""
def searchByParagraph(sentence, num_results=10):
	reference_embedding = get_embedding_similarity(sentence)

	# paragraphd
	# search similarity
	result = para_train_index.search(reference_embedding, num_results)
	reference_embedding_squeeze = reference_embedding.squeeze()
	result_texts = [para.loc[i]['paragraph'] for i in result[1][0]]
	result_embedding = [get_embedding(t).squeeze() for t in result_texts]
	result_similarity = [calculate_similarity(reference_embedding_squeeze, e) for e in result_embedding]

	# sort result_texts using result_similairty
	para_result_df = para.loc[result[1][0]]
	para_result_df['similarity'] = result_similarity
	para_result_df = para_result_df.sort_values('similarity', ascending=False)

	# merge with title
	para_result_df = pd.merge(para_result_df, title[['title_id', 'title']], on='title_id')
	para_result_df = para_result_df[['title_id','section_id', 'paragraph_id', 'title', 'section', 'paragraph', 'similarity']]

	return para_result_df

	"""### Find similar title_sec"""
def searchByTitleSec(sentence, num_results=10):
	reference_embedding = get_embedding_similarity(sentence)

	# search for title_sec similarity
	result  = titSec_train_index.search(reference_embedding, num_results)
	reference_embedding_squeeze = reference_embedding.squeeze()
	result_texts = [titSec.loc[i]['titSec'] for i in result[1][0]]
	result_embedding = [get_embedding(t).squeeze() for t in result_texts]
	result_similarity = [calculate_similarity(reference_embedding_squeeze, e) for e in result_embedding]

	# sort
	titSec_result_df = titSec.loc[result[1][0]]
	titSec_result_df['similarity'] = result_similarity
	titSec_result_df = titSec_result_df.sort_values('similarity', ascending=False)
	return titSec_result_df

